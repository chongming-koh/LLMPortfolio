{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1b4763-3445-48c9-b675-15cbaa0e9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from IPython.display import Markdown, display\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import OpenAI\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import gradio as gr # For Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf42ec1e-2d0d-4cbb-96fb-c65c6109cedf",
   "metadata": {},
   "source": [
    "# Connecting to Nebius LLM via API\n",
    "Setup connection to Nebius API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79655531-cddc-4642-bea5-45b4e78185c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the key file\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\vital\\\\PythonStuff\\\\keys\")\n",
    "cwd = os.getcwd() \n",
    "\n",
    "with open(\"nebius_api_key\", \"r\") as file:\n",
    "    nebius_api_key = file.read().strip()\n",
    "\n",
    "os.environ[\"NEBIUS_API_KEY\"] = nebius_api_key\n",
    "\n",
    "# Nebius uses the same OpenAI() class, but with additional details\n",
    "nebius_client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
    "    api_key=os.environ.get(\"NEBIUS_API_KEY\"),\n",
    ")\n",
    "\n",
    "llama_8b_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "llama_70b_model =\"meta-llama/Llama-3.3-70B-Instruct\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c381989e-4384-46a8-bd8b-7988c019f833",
   "metadata": {},
   "source": [
    "# A Class to represent a Webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822e0a5a-7c69-4b9e-b0cb-f0b30c7af0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.title = \"\"\n",
    "        self.text = \"\"\n",
    "        self.links = []   # NEW: store hyperlinks\n",
    "        self.scrape()\n",
    "\n",
    "    def scrape(self):\n",
    "        try:\n",
    "            # Chrome options\n",
    "            chrome_options = Options()\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "            chrome_options.add_argument(\"--no-sandbox\")\n",
    "            chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "            chrome_options.add_argument(\"--disable-gpu\")\n",
    "            chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "            chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "            # Try to find Chrome\n",
    "            chrome_paths = [\n",
    "                r\"C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\",\n",
    "                r\"C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe\",\n",
    "                r\"C:\\Users\\{}\\AppData\\Local\\Google\\Chrome\\Application\\chrome.exe\".format(os.getenv('USERNAME')),\n",
    "            ]\n",
    "\n",
    "            chrome_binary = None\n",
    "            for path in chrome_paths:\n",
    "                if os.path.exists(path):\n",
    "                    chrome_binary = path\n",
    "                    break\n",
    "\n",
    "            if chrome_binary:\n",
    "                chrome_options.binary_location = chrome_binary\n",
    "\n",
    "            # Create driver\n",
    "            driver = webdriver.Chrome(options=chrome_options)\n",
    "            driver.set_page_load_timeout(30)\n",
    "\n",
    "            #print(f\"üîç Loading: {self.url}\")\n",
    "            driver.get(self.url)\n",
    "\n",
    "            # Wait for page to load\n",
    "            time.sleep(5)\n",
    "\n",
    "            # Try to wait for main content\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"main\"))\n",
    "                )\n",
    "            except Exception:\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "                    )\n",
    "                except Exception:\n",
    "                    pass  # Continue anyway\n",
    "\n",
    "            # Get title and page source\n",
    "            self.title = driver.title\n",
    "            page_source = driver.page_source\n",
    "            driver.quit()\n",
    "\n",
    "            print(f\"‚úÖ Page loaded: {self.title}\")\n",
    "\n",
    "            # Parse with BeautifulSoup\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "            # Remove unwanted elements\n",
    "            for element in soup([\"script\", \"style\", \"img\", \"input\", \"button\", \"nav\", \"footer\", \"header\"]):\n",
    "                element.decompose()\n",
    "\n",
    "            # Get main content\n",
    "            main = soup.find('main') or soup.find('article') or soup.find('.content') or soup.find('body')\n",
    "            if main:\n",
    "                self.text = main.get_text(separator=\"\\n\", strip=True)\n",
    "            else:\n",
    "                self.text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "            # Clean up text\n",
    "            lines = [line.strip() for line in self.text.split('\\n') if line.strip() and len(line.strip()) > 2]\n",
    "            self.text = '\\n'.join(lines[:200])  # Limit to first 200 lines\n",
    "\n",
    "            #print(f\"üìÑ Extracted {len(self.text)} characters\")\n",
    "\n",
    "            # NEW: Extract hyperlinks\n",
    "            links = [a.get('href') for a in soup.find_all('a', href=True)]\n",
    "            # Filter out empty, javascript:, and mailto: links\n",
    "            self.links = [link for link in links if link and not link.startswith(('javascript:', 'mailto:'))]\n",
    "\n",
    "            #print(f\"üìÑ Extracted {len(self.text)} characters and {len(self.links)} links\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error occurred: {e}\")\n",
    "            self.title = \"Error occurred\"\n",
    "            self.text = \"Could not scrape website content\"\n",
    "            self.links = []\n",
    "        \n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d7f148-2524-4680-96a5-47981c83bb6a",
   "metadata": {},
   "source": [
    "# Build the system prompt for URL links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b8ac1a-38aa-4507-99f6-87763e8a40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "defineSystemPrompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "defineSystemPrompt += \"Your response must be valid JSON only.\\n\"\n",
    "defineSystemPrompt += \"Do not include any explanation, text, or Markdown code fences.\\n\"\n",
    "defineSystemPrompt += \"You MUST respond in JSON as in this example:\"\n",
    "defineSystemPrompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2c9f5-50e3-46c1-9a01-313cf4e2391c",
   "metadata": {},
   "source": [
    "# Build the user prompt for URL links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ed5590-e4fe-4f31-8592-259076ea1aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the user prompt for LLM\n",
    "def user_prompt_for_links(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"\\nplease decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format.\" \\\n",
    "                   \"\\nDo not include Terms of Service, Privacy, email links.\\n\"\n",
    "    \n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24446f0c-f703-4bba-8de1-e0c1c8d25267",
   "metadata": {},
   "source": [
    "# Function to chat with LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf843747-7ecb-428d-b3cf-ca5e56483242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_llm(prompt: str,\n",
    "                    system_prompt=\"You are a good assistant\",\n",
    "                    max_tokens=512,\n",
    "                    client=nebius_client,\n",
    "                    model=llama_8b_model,\n",
    "                    prettify=True,\n",
    "                    stream=True,\n",
    "                    temperature=None) -> str:\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    if system_prompt:\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            }\n",
    "        )\n",
    "\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    #if prettify:\n",
    "    #    return prettify_string(completion.choices[0].message.content)\n",
    "   # else:\n",
    "    \n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4355d-0948-4212-9e20-80be71190f41",
   "metadata": {},
   "source": [
    "# The function that helps to get relevant links by calling the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d36e561a-19a0-4d87-9b09-8226b39a3eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinks(url):\n",
    "    website = Website(url)\n",
    "    prompt = user_prompt_for_links(website)\n",
    "    rawResponse = answer_with_llm(prompt,defineSystemPrompt)\n",
    "    try:\n",
    "        # Convert JSON string into a Python dict\n",
    "        return json.loads(rawResponse)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"‚ùå LLM did not return valid JSON\")\n",
    "        return {\"links\": []}\n",
    "    #return answer_with_llm(prompt,defineSystemPrompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c169569-c645-4a12-9ddb-802b275f85bb",
   "metadata": {},
   "source": [
    "# Invoke action to view all links gathered from the website and view in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a1638db-9e72-4b92-9e1d-ce1d59ad064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getLinks(\"https://www.citigroup.com/global/businesses/services\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef50fef-bf1e-469b-ae8f-b2b5df49d6d2",
   "metadata": {},
   "source": [
    "# Build the brochure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb224b6-7387-4673-b502-4c29cc203850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is call by get_brochure_user_prompt function. Then in this function, it will creates an instance of your Website class.\n",
    "#The Website constructor calls its own self.scrape() method ‚Äî\n",
    "#launching Selenium to load the page, wait for <body>, and extract text and links.\n",
    "#The scraped title, main body text, and links are stored in self.title, self.text, and self.links.\n",
    "#Next, it will call the getLinks function where getLinks(url) asks LLM which links are relevant\n",
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = getLinks(url)\n",
    "\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result\n",
    "\n",
    "#print(get_all_details(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17721e82-7ce6-46b8-b5ac-a456e1cd7cf6",
   "metadata": {},
   "source": [
    "# Using Gradio to generate Brochure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca9a1fec-7ef1-457b-a86e-12653b07cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model_choice):\n",
    "    yield f\"### Generating brochure for {company_name} using {model_choice}...\\n\"\n",
    "    try:\n",
    "        # Step 1: Scrape and collect all website content\n",
    "        content = get_all_details(url)\n",
    "\n",
    "        # Step 2: Select model based on user input\n",
    "        model_map = {\n",
    "            \"Llama 8B\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "            \"Llama 70B\": \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "            \"Gemma 9B\": \"google/gemma-2-9b-it-fast\",\n",
    "            \"Qwen 72B\": \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "        }\n",
    "        selected_model = model_map.get(model_choice, \"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "\n",
    "        # Step 3: Build the prompts\n",
    "        system_prompt = (\n",
    "            \"You are an assistant that analyzes several company pages and writes a short brochure in markdown, \"\n",
    "            \"highlighting its business focus, culture, customers, and career opportunities.\"\n",
    "        )\n",
    "\n",
    "        user_prompt = (\n",
    "            f\"You are looking at {company_name}.\\n\"\n",
    "            f\"Use the following website information to create a short, professional brochure in markdown.\\n\"\n",
    "            f\"{content[:5000]}\"\n",
    "        )\n",
    "\n",
    "        # Step 4: Stream LLM output token-by-token\n",
    "        stream_resp = nebius_client.chat.completions.create(\n",
    "            model=selected_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            max_tokens=1024,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        full_text = \"\"\n",
    "        for chunk in stream_resp:\n",
    "            if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
    "                token = chunk.choices[0].delta.content\n",
    "                full_text += token\n",
    "                yield full_text  # live update in Gradio\n",
    "\n",
    "        yield full_text\n",
    "\n",
    "    except Exception as e:\n",
    "        yield f\"‚ùå Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc41e868-1679-4744-b0aa-a21cc3c72ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Company name:\"),\n",
    "        gr.Textbox(label=\"Landing page URL including http:// or https://\"),\n",
    "        gr.Dropdown([\"llama_8b_model\", \"llama_70b_model\"], label=\"Select model\")],\n",
    "    outputs=[gr.Markdown(label=\"Brochure:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch(inbrowser=True)\n",
    "#llama_8b_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "#llama_70b_model =\"meta-llama/Llama-3.3-70B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a54c8-746a-4130-905b-52eff7aa717f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
